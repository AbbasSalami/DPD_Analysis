{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d034e5e3",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a083990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import matplotlib.image as mpimg\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Input, Flatten, Dropout, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, SeparableConv2D, AveragePooling2D, Activation\n",
    "\n",
    "import scipy\n",
    "from scipy import stats, fft, signal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415a3c0",
   "metadata": {},
   "source": [
    "### Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7908002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed parameters\n",
    "#--------------------\n",
    "Fs = 250                # Dataset sampling frequency\n",
    "start_sample = -100     # Start of the tiral (ms after the cue)\n",
    "n_channel = 60          # Number of EEG channels\n",
    "\n",
    "# Hyperparameters\n",
    "#--------------------\n",
    "F1 = 4              # Number of frequency filters\n",
    "D = 2               # Number of spatial filters in each frequency sub-band\n",
    "F2 = F1*D           # Number of SeparableConv2D filters\n",
    "T1 = 128            # Temporal kernel size (samples) in the first convolution\n",
    "T2 = 32             # Temporal kernel size (samples) in SeparableConv2D\n",
    "drop_rate = 0.2     # Droupout rate\n",
    "Thr_proposed = 56   # Proposed CDS threshold\n",
    "Thr_common = 50     # Common CDS threshold being used in the literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9457ab61",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843affa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "print('loading the dataset ... ')\n",
    "npzfile = np.load('./DPD_processed_data.npz', allow_pickle=True) \n",
    "X = npzfile['X']\n",
    "dtmep = {}\n",
    "for key in X.item().keys():\n",
    "    dtmep[key] = X.item()[key]\n",
    "X = dtmep           # EEG data\n",
    "Y = npzfile['Y']    # CDS scores\n",
    "Z = npzfile['Z']    # User ID\n",
    "\n",
    "# Changing data format and extracting data subset\n",
    "for key in X.keys():\n",
    "    X[key] = np.float32(X[key])\n",
    "    X[key] = np.transpose(X[key], (2, 0, 1))\n",
    "    X[key] = X[key][:,:,:,np.newaxis]\n",
    "Y = np.squeeze(np.float32(Y))\n",
    "Z = np.squeeze(Z)\n",
    "\n",
    "X_original = copy.deepcopy(X)\n",
    "X = np.stack((X['Left_touch'], X['Right_touch']), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab2112",
   "metadata": {},
   "source": [
    "### Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(Chans, Samples, out_type = 'train'):\n",
    "    #=======================================================================================\n",
    "    # Network layers analysing left-hand touch\n",
    "    #=======================================================================================\n",
    "    left_input = Input(shape = (Chans, Samples, 1))\n",
    "    block1 = Conv2D(F1, (1, T1), use_bias = False, activation = 'linear', padding='same', kernel_initializer = 'he_normal',\n",
    "                   name = 'Spectral_filter_left')(left_input)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Dropout(drop_rate)(block1)\n",
    "    block1 = DepthwiseConv2D((Chans, 1), use_bias = False, padding='valid', depth_multiplier = D, activation = 'linear',\n",
    "                             depthwise_constraint = tf.keras.constraints.MaxNorm(max_value=1), \n",
    "                             depthwise_initializer = 'he_normal', \n",
    "                            name = 'Spatial_filter_left')(block1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    source_left = block1\n",
    "\n",
    "    block1 = AveragePooling2D((1, 2))(block1)\n",
    "    block1 = Dropout(drop_rate)(block1)\n",
    "\n",
    "    block1 = SeparableConv2D(F2, (1, T2), use_bias = False, activation = 'linear', padding = 'same' ,\n",
    "                            kernel_initializer = 'he_normal')(block1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    block1 = AveragePooling2D((1, 4))(block1)\n",
    "    block1 = Dropout(drop_rate)(block1)\n",
    "    \n",
    "    embedded_left    = Flatten(name = 'Embedded_left')(block1)\n",
    "    \n",
    "    #=======================================================================================\n",
    "    # Network layers analysing right-hand touch\n",
    "    #=======================================================================================\n",
    "    \n",
    "    right_input = Input(shape = (Chans, Samples, 1))\n",
    "    block2 = Conv2D(F1, (1, T1), use_bias = False, activation = 'linear', padding='same', kernel_initializer = 'he_normal',\n",
    "                   name = 'Spectral_filter_right')(right_input)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Dropout(drop_rate)(block2)\n",
    "    block2 = DepthwiseConv2D((Chans, 1), use_bias = False, padding='valid', depth_multiplier = D, activation = 'linear',\n",
    "                             depthwise_constraint = tf.keras.constraints.MaxNorm(max_value=1),\n",
    "                             depthwise_initializer = 'he_normal', \n",
    "                            name = 'Spatial_filter_right')(block2)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    source_right = block2\n",
    "\n",
    "    block2 = AveragePooling2D((1, 2))(block2)\n",
    "    block2 = Dropout(drop_rate)(block2)\n",
    "\n",
    "    block2 = SeparableConv2D(F2, (1, T2), use_bias = False, activation = 'linear', padding = 'same',\n",
    "                            kernel_initializer = 'he_normal')(block2)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((1, 4))(block2)\n",
    "    block2 = Dropout(drop_rate)(block2)\n",
    "    \n",
    "    embedded_right    = Flatten(name = 'Embedded_right')(block2)\n",
    "\n",
    "    #=======================================================================================\n",
    "    # Concatenating low-dimensional representation of left and right touch\n",
    "    #=======================================================================================    \n",
    "    embedded = Concatenate(axis = -1)([embedded_left, embedded_right])\n",
    "    \n",
    "    reg         = Dense(1, use_bias = False, activation = 'relu', kernel_regularizer = tf.keras.regularizers.L2(), \n",
    "                        name = 'Regression')(embedded)\n",
    "    \n",
    "    clustering  = Dense(2, use_bias = False, activation = 'softmax',\n",
    "                        kernel_constraint = tf.keras.constraints.NonNeg(),\n",
    "                        name='Clustering')(embedded)\n",
    "    \n",
    "    if out_type == 'evaluation':\n",
    "        return Model(inputs = [left_input, right_input], outputs = [reg, clustering, embedded, source_left, source_right])\n",
    "\n",
    "    else:\n",
    "        return Model(inputs = [left_input, right_input], outputs = [reg, clustering])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d4129",
   "metadata": {},
   "source": [
    "### Low-dimensional representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model and loading trained weights\n",
    "_, Chans, Samples, _, _ = X.shape\n",
    "model = Network(Chans, Samples, out_type = 'evaluation')\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Concatenating the two types of input to form a single input tensor\n",
    "All_input = [X[:,:,:,:,0],X[:,:,:,:,1]]\n",
    "\n",
    "# Initialising subplots\n",
    "fig, ax = plt.subplots(2,2, figsize=(15,15))\n",
    "def axs_info(title, axs_id):\n",
    "    ax[axs_id[0],axs_id[1]].set_title(title, fontsize= 13)\n",
    "    ax[axs_id[0],axs_id[1]].legend(fontsize= 16)\n",
    "    ax[axs_id[0],axs_id[1]].set_xlabel('PC1', fontsize= 18)\n",
    "    ax[axs_id[0],axs_id[1]].set_ylabel('PC2', fontsize= 18)\n",
    "    ax[axs_id[0],axs_id[1]].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "# Scatter plot based on:\n",
    "#------------------------------------------------------------------------\n",
    "# the output of clustering analysis/branch\n",
    "#------------------------------------------------------------------------\n",
    "Embedded = model(All_input)[2].numpy()\n",
    "labels = np.argmax(model(All_input)[1].numpy(),axis=1)\n",
    "Cluster_labels = [stats.mode(i).mode for i in [labels[Z==i] for i in np.unique(Z)]]\n",
    "C1_sub = np.unique(Z)[np.squeeze(Cluster_labels) == 0]\n",
    "C2_sub = np.unique(Z)[np.squeeze(Cluster_labels) == 1]\n",
    "C1_idx = np.array([i in C1_sub for i in Z])\n",
    "C2_idx = np.array([i in C2_sub for i in Z])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(Embedded)\n",
    "Embedded_temp = pca.transform(Embedded)\n",
    "\n",
    "if len(np.unique(labels))>1:\n",
    "    ax[0,0].scatter(Embedded_temp[(labels==0),0],Embedded_temp[(labels==0),1], c = 'y', s =1, marker='o',\n",
    "                label='Cluster 1')\n",
    "    ax[0,0].scatter(Embedded_temp[(labels==1),0],Embedded_temp[(labels==1),1], c = 'm', s =1, marker='o',\n",
    "                label='Cluster 2')\n",
    "else:\n",
    "    if np.unique(labels)==0: \n",
    "        ax[0,0].scatter(Embedded_temp[(labels==0),0],Embedded_temp[(labels==0),1], c = 'y', s =1, marker='o',\n",
    "                    label='Cluster 1')\n",
    "        print('\\nAll the training trials have been assigned to the cluster 1')\n",
    "    elif np.unique(labels)==1:\n",
    "        ax[0,0].scatter(Embedded_temp[(labels==1),0],Embedded_temp[(labels==1),1], c = 'm', s =1, marker='o',\n",
    "                    label='Cluster 2')   \n",
    "        print('\\nAll the training trials have been assigned to the cluster 2')\n",
    "\n",
    "axs_info('Clustering analysis of the network', [0,0])\n",
    "\n",
    "# Scatter plot based on:\n",
    "#------------------------------------------------------------------------\n",
    "# K-means on latent representation\n",
    "#------------------------------------------------------------------------\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(Embedded)\n",
    "labels = kmeans.predict(Embedded)\n",
    "ax[0,1].scatter(Embedded_temp[(labels==0),0],Embedded_temp[(labels==0),1], c = 'y', s =1, marker='o',\n",
    "            label='Cluster 1')\n",
    "ax[0,1].scatter(Embedded_temp[(labels==1),0],Embedded_temp[(labels==1),1], c = 'm', s =1, marker='o',\n",
    "            label='Cluster 2')\n",
    "\n",
    "axs_info('K-means on low-dimensional representation', [0,1])   \n",
    "\n",
    "# Scatter plot based on:\n",
    "#------------------------------------------------------------------------\n",
    "# the output of regression analysis/branch with the proposed threshold of 56\n",
    "#------------------------------------------------------------------------\n",
    "labels = np.squeeze(model(All_input)[0].numpy())\n",
    "Reg_labels = [np.mean(i) for i in [labels[Z==i] for i in np.unique(Z)]]\n",
    "DPD_sub = np.unique(Z)[np.squeeze(Reg_labels) >= Thr_proposed]\n",
    "control_sub = np.unique(Z)[np.squeeze(Reg_labels) < Thr_proposed]\n",
    "DPD_idx = np.array([i in DPD_sub for i in Z])\n",
    "control_idx = np.array([i in control_sub for i in Z])\n",
    "\n",
    "ax[1,0].scatter(Embedded_temp[labels<Thr_proposed,0],\n",
    "            Embedded_temp[labels<Thr_proposed,1],\n",
    "            c = 'b', s =1, marker='o',label='Control group')\n",
    "\n",
    "ax[1,0].scatter(Embedded_temp[labels>=Thr_proposed,0],\n",
    "            Embedded_temp[labels>=Thr_proposed,1],\n",
    "            c = 'r', s =1, marker='o', label='DPD group')\n",
    "\n",
    "axs_info('Regression analysis of the network' +' \\\\ Proposed CDS score threshold:' + str(Thr_proposed), [1,0])   \n",
    "\n",
    "# Scatter plot based on:\n",
    "#------------------------------------------------------------------------\n",
    "# reported CDS scores with the common threshold of 50\n",
    "#------------------------------------------------------------------------\n",
    "ax[1,1].scatter(Embedded_temp[np.squeeze(Y<Thr_common),0],\n",
    "            Embedded_temp[np.squeeze(Y<Thr_common),1],\n",
    "            c = 'b', s =1, marker='o',label='Control group')\n",
    "\n",
    "ax[1,1].scatter(Embedded_temp[np.squeeze(Y>=Thr_common),0],\n",
    "            Embedded_temp[np.squeeze(Y>=Thr_common),1],\n",
    "            c = 'r', s =1, marker='o', label='DPD group')\n",
    "\n",
    "axs_info('Original scores' +' \\\\ CDS Score threshold:' + str(Thr_common), [1,1])   \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc03507",
   "metadata": {},
   "source": [
    "### Network visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65460f58",
   "metadata": {},
   "source": [
    "##### Custom functions needed for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise spatial weights\n",
    "def NormalizeData(data, names, T_type):\n",
    "    N_list = [0,0]\n",
    "    for f in range(F1):\n",
    "        weights_spat = []\n",
    "        for d in range(D):\n",
    "            spat_name = 'Spatial_filter_' + T_type + '/depthwise_kernel:0'\n",
    "            weights_spat_temp = model.get_weights()[names.index(spat_name)][:,:,f,d]\n",
    "            weights_spat_temp = np.squeeze(weights_spat_temp)\n",
    "            try: \n",
    "                weights_spat = np.vstack((weights_spat,weights_spat_temp))\n",
    "            except:\n",
    "                weights_spat = weights_spat_temp\n",
    "\n",
    "\n",
    "        try:\n",
    "            weights_spat = np.linalg.pinv(weights_spat)\n",
    "        except:\n",
    "            weights_spat = weights_spat[np.newaxis,:]\n",
    "            weights_spat = np.linalg.pinv(weights_spat)\n",
    "\n",
    "        weights_spat = np.abs(weights_spat)\n",
    "\n",
    "        N_list[0] = np.minimum(np.min(weights_spat),N_list[0])\n",
    "        N_list[1] = np.maximum(np.max(weights_spat),N_list[1])\n",
    "    \n",
    "    return (data - N_list[0]) / (N_list[1] - N_list[0])\n",
    "\n",
    "# Fast Fourier transform function\n",
    "def FFT(t, y):\n",
    "    n = len(t)\n",
    "    Δ = (max(t) - min(t)) / (n-1)\n",
    "    k = int(n/2)\n",
    "    f = np.arange(k) / (n*Δ)\n",
    "    Y = abs(fft.fft(y))[:k]\n",
    "    return (f, Y)\n",
    "\n",
    "# Plot axis configuration\n",
    "def ax_info(axes, title, S1, S2, ax_id):\n",
    "    axes[ax_id].legend(fontsize = 15, loc='best')\n",
    "    axes[ax_id].axvline(x=0, c = 'k', ls = 'dashed')\n",
    "    axes[ax_id].axhline(y=0, c = 'k', ls = 'dashed')\n",
    "    axes[ax_id].set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf04c4",
   "metadata": {},
   "source": [
    "##### Choosing trial type and returning subject assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_type = input('Which type of trials do you want to visualsie (left - right)? ')\n",
    "\n",
    "# Showing subjects' ID assigned to each group\n",
    "print('\\nBased on \\033[1m clustering \\033[0m analysis ...')\n",
    "print(len(C1_sub), 'subjects in cluster 1: ', [int(i) for i in C1_sub])\n",
    "print(len(C2_sub), 'subjects in cluster 2: ', [int(i) for i in C2_sub])\n",
    "print('\\nBased on \\033[1m regressions \\033[0m analysis ...')\n",
    "print(len(control_sub), 'subjects in the control group: ', [int(i) for i in control_sub])\n",
    "print(len(DPD_sub), 'subjects in the DPD group: ', [int(i) for i in DPD_sub])\n",
    "report_labels = [np.mean(i) for i in [Y[Z==i] for i in np.unique(Z)]]\n",
    "DPD_sub_act = np.unique(Z)[np.squeeze(report_labels) >= Thr_common]\n",
    "control_sub_act = np.unique(Z)[np.squeeze(report_labels) < Thr_common]\n",
    "DPD_idx_act = np.array([i in DPD_sub_act for i in Z])\n",
    "control_idx_act = np.array([i in control_sub_act for i in Z])\n",
    "print('\\nBased on \\033[1m reported \\033[0m scores ...')\n",
    "print(len(control_sub_act), 'subjects in the control group: ', [int(i) for i in control_sub_act])\n",
    "print(len(DPD_sub_act), 'subjects in the DPD group: ', [int(i) for i in DPD_sub_act], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6221f87",
   "metadata": {},
   "source": [
    "##### Spectral and spatial information visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5c27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\033[1m' + 'Visualising sources obtained for ' + T_type + ' touch/no_touch trials ... ' + '\\033[0m\\n')\n",
    "# Loading channel location\n",
    "loc = mne.channels.read_custom_montage('Channel_locations_30.loc', coord_frame = 'head')\n",
    "loc_info = mne.create_info(loc.ch_names, sfreq=Fs, ch_types='eeg')\n",
    "fig, axes = plt.subplots(figsize=(18, 5), nrows=D+1, ncols=F1)\n",
    "\n",
    "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
    "weights = model.get_weights()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Spectral information visualisation\n",
    "#------------------------------------------------------------------------\n",
    "counter = 1\n",
    "for f in range(F1):\n",
    "    spec_name = 'Spectral_filter_' + T_type + '/kernel:0'\n",
    "    weights_freq = model.get_weights()[names.index(spec_name)][:,:,:,f]\n",
    "    weights_freq = np.squeeze(weights_freq)\n",
    "    weights_freq = weights_freq-np.mean(weights_freq)\n",
    "    t = np.linspace(0, weights_freq.size/Fs, num=weights_freq.size)\n",
    "    y = weights_freq[::-1]\n",
    "    (F, FFT_out) = FFT(t, y)\n",
    "    FFT_out = scipy.signal.savgol_filter(FFT_out, 25,8)\n",
    "\n",
    "\n",
    "    axes[0,f].plot(F[1:int(len(F)/3)], FFT_out[1:int(len(F)/3)], c = 'k')\n",
    "    axes[0,f].set_title('Frequency filter {}'.format(f), fontsize=13)\n",
    "    axes[0,f].set_yticks([])\n",
    "    axes[0,f].vlines([1,3,7.5,13,30], min(FFT_out[1:int(len(F)/3)]), max(FFT_out[1:int(len(F)/3)]), \n",
    "                     'r', alpha = 0.8, linestyles = 'dashed')\n",
    "\n",
    "    #------------------------------------------------------------------------\n",
    "    # Spatial information visualisation\n",
    "    #------------------------------------------------------------------------\n",
    "    weights_spat = []\n",
    "    for d in range(D):\n",
    "        spat_name = 'Spatial_filter_' + T_type + '/depthwise_kernel:0'\n",
    "        weights_spat_temp = model.get_weights()[names.index(spat_name)][:,:,f,d]\n",
    "        weights_spat_temp = np.squeeze(weights_spat_temp)\n",
    "        try: \n",
    "            weights_spat = np.vstack((weights_spat,weights_spat_temp))\n",
    "        except:\n",
    "            weights_spat = weights_spat_temp\n",
    "\n",
    "    try:\n",
    "        weights_spat = np.linalg.pinv(weights_spat)\n",
    "    except:\n",
    "        weights_spat = weights_spat[np.newaxis,:]\n",
    "        weights_spat = np.linalg.pinv(weights_spat)\n",
    "        if f == 0:\n",
    "            print('There is only one spatial filter or the inverse of the weight matrix does not exists')\n",
    "\n",
    "\n",
    "    for d in range(D):\n",
    "        weights_spat_temp = weights_spat[:,d]\n",
    "        weights_spat_temp = weights_spat_temp[:,np.newaxis]\n",
    "        \n",
    "        weights_spat_temp = np.abs(weights_spat_temp)\n",
    "        weights_spat_temp = NormalizeData(weights_spat_temp, names, T_type)\n",
    "        \n",
    "        fake_evoked = mne.EvokedArray(weights_spat_temp, loc_info)\n",
    "        fake_evoked.set_montage(loc)\n",
    "\n",
    "        im,cm = mne.viz.plot_topomap(np.squeeze(fake_evoked.data), fake_evoked.info, axes=axes[d+1,f], \n",
    "                             cmap = 'Greens',\n",
    "                             show=False, outlines = 'head', contours= 2, res = 100)\n",
    "        axes[d+1,f].set_ylabel('Source '+str(counter), fontsize = 13)\n",
    "        counter+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace5af9",
   "metadata": {},
   "source": [
    "##### Temporal information visualisation in the source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SourceVis = int(input('\\nWhich of the above sources do you want to analyse? (insert 0 to stop) '))\n",
    "\n",
    "if T_type=='left':\n",
    "    s_signal = np.squeeze(model(All_input)[3].numpy()[:,:,:,SourceVis-1])\n",
    "\n",
    "elif T_type=='right':\n",
    "    s_signal = np.squeeze(model(All_input)[4].numpy()[:,:,:,SourceVis-1])\n",
    "\n",
    "fig_temp, axes_temp = plt.subplots(figsize=(22, 5), nrows=1, ncols=3)\n",
    "t_trial = np.linspace(-100,400,s_signal.shape[-1])\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "axes_temp[0].plot(t_trial, np.mean(s_signal[C1_idx], axis = 0), 'y', label = 'Cluster 1')\n",
    "error = np.std(s_signal[C1_idx], axis = 0)\n",
    "axes_temp[0].fill_between(t_trial, np.mean(s_signal[C1_idx], axis = 0)-error, \n",
    "                            np.mean(s_signal[C1_idx], axis = 0)+error, alpha = 0.1, color = 'y')\n",
    "\n",
    "axes_temp[0].plot(t_trial, np.mean(s_signal[C2_idx], axis = 0), 'm', label = 'Cluster 2')\n",
    "error = np.std(s_signal[C2_idx], axis = 0)\n",
    "axes_temp[0].fill_between(t_trial, np.mean(s_signal[C2_idx], axis = 0)-error, \n",
    "                            np.mean(s_signal[C2_idx], axis = 0)+error, alpha = 0.1, color = 'm')\n",
    "\n",
    "ax_info(axes_temp, 'Based on clustering analysis', s_signal[C1_idx], s_signal[C2_idx], 0)\n",
    "axes_temp[0].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "axes_temp[1].plot(t_trial, np.mean(s_signal[DPD_idx], axis = 0), 'r', label = 'DPD')\n",
    "error = np.std(s_signal[DPD_idx], axis = 0)\n",
    "axes_temp[1].fill_between(t_trial, np.mean(s_signal[DPD_idx], axis = 0)-error, \n",
    "                            np.mean(s_signal[DPD_idx], axis = 0)+error, alpha = 0.1, color = 'r')\n",
    "\n",
    "axes_temp[1].plot(t_trial, np.mean(s_signal[control_idx], axis = 0), 'b', label = 'Control')\n",
    "error = np.std(s_signal[control_idx], axis = 0)\n",
    "axes_temp[1].fill_between(t_trial, np.mean(s_signal[control_idx], axis = 0)-error, \n",
    "                            np.mean(s_signal[control_idx], axis = 0)+error, alpha = 0.1, color = 'b')\n",
    "\n",
    "ax_info(axes_temp, 'Based on regressions analysis', s_signal[DPD_idx], s_signal[control_idx], 1)\n",
    "axes_temp[1].tick_params(axis='both', labelsize=15)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "axes_temp[2].plot(t_trial, np.mean(s_signal[DPD_idx_act], axis = 0), 'r', label = 'DPD')\n",
    "error = np.std(s_signal[DPD_idx_act], axis = 0)\n",
    "axes_temp[2].fill_between(t_trial, np.mean(s_signal[DPD_idx_act], axis = 0)-error, \n",
    "                            np.mean(s_signal[DPD_idx_act], axis = 0)+error, alpha = 0.1, color = 'r')\n",
    "\n",
    "axes_temp[2].plot(t_trial, np.mean(s_signal[control_idx_act], axis = 0), 'b', label = 'Control')\n",
    "error = np.std(s_signal[control_idx_act], axis = 0)\n",
    "axes_temp[2].fill_between(t_trial, np.mean(s_signal[control_idx_act], axis = 0)-error, \n",
    "                            np.mean(s_signal[control_idx_act], axis = 0)+error, alpha = 0.1, color = 'b')\n",
    "\n",
    "ax_info(axes_temp, 'Based on reported scores', s_signal[DPD_idx_act], s_signal[control_idx_act], 2)\n",
    "axes_temp[2].tick_params(axis='both', labelsize=15)\n",
    "plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Performing statistical analysis in the source domain\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "t_range = input('\\nSelect time window for statistical test (low-high) >> (insert 0 to skip) ')\n",
    "if t_range!= '0':\n",
    "    [low, high] = [int((float(i)-start_sample)*Fs/1000) for i in t_range.split('-')]\n",
    "    \n",
    "    print(\"\"\"\\nThe independent t-test to analyse source %d between groups in %sms time window:\\np-values\\n\n",
    "    Clustering analysis:\\t%2.5f\n",
    "    Regressions analysis:\\t%2.5f\n",
    "    Reported scores:\\t%2.5f\"\"\"\n",
    "    % (SourceVis, t_range,\n",
    "        stats.ttest_ind([np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in C1_sub]]]],\n",
    "                        [np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in C2_sub]]]]).pvalue,\n",
    "        stats.ttest_ind([np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in DPD_sub]]]],\n",
    "                        [np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in control_sub]]]]).pvalue,\n",
    "        stats.ttest_ind([np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in np.unique(Z[Y>=Thr_common])]]]],\n",
    "                        [np.mean(i[low:high]) for i in \\\n",
    "                        [np.mean(i,0) for i in [s_signal[i] for i in [Z==i for i in np.unique(Z[Y<Thr_common])]]]]).pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d1dd0",
   "metadata": {},
   "source": [
    "##### Temporal information visualisation in the electrode domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing channel locations\n",
    "plt.figure(figsize = (16,8), dpi=100)\n",
    "img = mpimg.imread('Channel_loc_30.PNG')\n",
    "imgplot = plt.imshow(img, interpolation='none')\n",
    "plt.show()\n",
    "\n",
    "print('\\n\\033[1m' + 'Analysing average ERPs in the electrode domain for ' + T_type + ' touch/no_touch trials ... ' + '\\033[0m\\n')\n",
    "Channel_in = input('Which channels do you want to visualsie (use numbers seperated by comma)? ')   \n",
    "Channel = Channel_in.split(',')\n",
    "Channel = np.array([int(i)-1 for i in Channel])\n",
    "\n",
    "L_T = X_original['Left_touch']\n",
    "L_NT = X_original['Left_no_touch']\n",
    "R_T = X_original['Right_touch']\n",
    "R_NT = X_original['Right_no_touch']\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(22, 16), nrows=3, ncols=3)\n",
    "if T_type== 'left':\n",
    "    touch_signal = L_T\n",
    "    no_touch_signal = L_NT\n",
    "elif T_type== 'right':\n",
    "    touch_signal = R_T\n",
    "    no_touch_signal = R_NT\n",
    "    \n",
    "#------------------------------------------------------------------------\n",
    "# Defining functions needed for visualisation\n",
    "#------------------------------------------------------------------------\n",
    "# Calculating average ERPs \n",
    "def Ave_ERP(signal, sub_idx, Channel):\n",
    "    All_touch_list = [np.mean(i,0) for i in [signal[i] for i in [Z==i for i in sub_idx]]]\n",
    "    All_touch = np.zeros(All_touch_list[0].shape)\n",
    "    counter = 0 \n",
    "    for item in All_touch_list:\n",
    "        All_touch += item\n",
    "        counter += 1\n",
    "    All_touch /= counter\n",
    "    return np.mean(All_touch[Channel,:,0], 0)\n",
    "\n",
    "def Time_vis1(g1_sub, g2_sub, idx, title, head1, head2, c1='r', c2='b'):\n",
    "    axes[0,idx].plot(t_trial, Ave_ERP(touch_signal, g1_sub, Channel), c1, label = head1)\n",
    "    axes[0,idx].plot(t_trial, Ave_ERP(touch_signal, g2_sub, Channel), c2, label = head2)\n",
    "    axes[0,idx].vlines(0, np.min(Ave_ERP(touch_signal, g1_sub, Channel)), \n",
    "                     np.max(Ave_ERP(touch_signal, g1_sub, Channel))\n",
    "                     , colors = 'y', linestyles = 'dashed')\n",
    "    axes[0,idx].set_title(title, fontweight='bold')\n",
    "    axes[0,idx].legend()\n",
    "    axes[0,idx].grid()\n",
    "    \n",
    "\n",
    "def Time_vis2(g1_sub, g2_sub, idx, title, head1, head2):\n",
    "    axes[1,idx].plot(t_trial, Ave_ERP(touch_signal, g1_sub, Channel), 'k', label = 'Touch')\n",
    "    axes[1,idx].plot(t_trial, Ave_ERP(no_touch_signal, g1_sub, Channel), 'r', label = 'No touch')\n",
    "    axes[1,idx].set_title('\\n'+head1, fontweight='bold')\n",
    "    axes[1,idx].vlines(0, np.min(Ave_ERP(touch_signal, g1_sub, Channel)), \n",
    "                     np.max(Ave_ERP(touch_signal, g1_sub, Channel))\n",
    "                     , colors = 'y', linestyles = 'dashed')\n",
    "    axes[1,idx].legend()\n",
    "    axes[1,idx].grid()\n",
    "\n",
    "    axes[2,idx].plot(t_trial, Ave_ERP(touch_signal, g2_sub, Channel), 'k', label = 'Touch')\n",
    "    axes[2,idx].plot(t_trial, Ave_ERP(no_touch_signal, g2_sub, Channel), 'r', label = 'No touch')\n",
    "    axes[2,idx].set_title(head2, fontweight='bold')\n",
    "    axes[2,idx].vlines(0, np.min(Ave_ERP(touch_signal, g2_sub, Channel)), \n",
    "                     np.max(Ave_ERP(touch_signal, g2_sub, Channel))\n",
    "                     , colors = 'y', linestyles = 'dashed')\n",
    "    axes[2,idx].legend()\n",
    "    axes[2,idx].grid()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "\n",
    "Time_vis1(C1_sub, C2_sub, 0, 'Clustering analysis', 'Cluster 1', 'Cluster 2', 'y', 'm')\n",
    "Time_vis1(DPD_sub, control_sub, 1, 'Regressions analysis', 'DPD group', 'control group')\n",
    "Time_vis1(DPD_sub_act, control_sub_act, 2, 'Reported scores', 'DPD group', 'control group')\n",
    "    \n",
    "Time_vis2(C1_sub, C2_sub, 0, 'Clustering analysis', 'Cluster 1', 'Cluster 2')\n",
    "Time_vis2(control_sub, DPD_sub, 1, 'Regressions analysis', 'control group', 'DPD group')\n",
    "Time_vis2(control_sub_act, DPD_sub_act, 2, 'Reported scores', 'control group', 'DPD group')\n",
    "plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Performing statistical analysis in the electrode domain\n",
    "#------------------------------------------------------------------------\n",
    "t_range = input('\\nSelect time window for statistical test (low-high) >> (insert 0 to skip) ')\n",
    "if t_range!= '0':\n",
    "    [low, high] = [int((float(i)-start_sample)*Fs/1000) for i in t_range.split('-')]\n",
    "\n",
    "    print(\"\"\"\\nThe independent t-test to analyse channels %r between groups in %sms time window:\\np_value\\n\n",
    "    Clustering analysis:\\t%2.5f\n",
    "    Regressions analysis:\\t%2.5f\n",
    "    Reported scores:\\t%2.5f\"\"\"\n",
    "    % (Channel_in, t_range,\n",
    "       stats.ttest_ind([np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in C1_sub]]]],\n",
    "                       [np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in C2_sub]]]]).pvalue,\n",
    "       stats.ttest_ind([np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in DPD_sub]]]],\n",
    "                       [np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in control_sub]]]]).pvalue,\n",
    "       stats.ttest_ind([np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in np.unique(Z[Y>=Thr_common])]]]],\n",
    "                       [np.mean(i[Channel,low:high,:]) for i in \\\n",
    "                        [np.mean(i,0) for i in [touch_signal[i] for i in [Z==i for i in np.unique(Z[Y<Thr_common])]]]]).pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d3f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
